{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1bee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4f80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_builder import model_builder, relabel, class_merger, balancer\n",
    "import tools_keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import resnet_v2, vgg19, efficientnet\n",
    "\n",
    "random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea11dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {\n",
    "    'chips': \"../../chips_gb/32_shuffled/\",\n",
    "    'chips_combined': \"../../chips_gb/32_shuffled_combined_12_named/\",\n",
    "    'chips_balanced': \"../../chips_gb/32_shuffled_sample_12_named/\",\n",
    "    'folder': \"../../urbangrammar_samba/spatial_signatures/ai/gb_32_sample/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611a75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping = [\n",
    "    ['9_0', '9_1', '9_2', '9_4', '9_5'],\n",
    "    ['2_0'], \n",
    "    ['2_1'], \n",
    "    ['2_2'],\n",
    "    ['1_0'], \n",
    "    ['3_0'], \n",
    "    ['5_0'], \n",
    "    ['6_0'], \n",
    "    ['8_0'],\n",
    "    ['0_0'],\n",
    "    ['4_0'],\n",
    "    ['7_0']\n",
    "]\n",
    "\n",
    "group_naming = [\n",
    "    \"Urbanity\", \n",
    "    \"Dense residential neighbourhoods\",\n",
    "    \"Connected residential neighbourhoods\",\n",
    "    \"Dense urban neighbourhoods\",\n",
    "    \"Accessible suburbia\",\n",
    "    \"Open sprawl\",\n",
    "    \"Warehouse_Park land\",\n",
    "    \"Gridded residential quarters\",\n",
    "    \"Disconnected suburbia\",\n",
    "    \"Countryside agriculture\", \n",
    "    \"Wild countryside\", \n",
    "    \"Urban buffer\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078a3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subset in [\"train\", \"validation\", \"secret\"]:\n",
    "#     total = 3500 if subset == \"train\" else 500\n",
    "#     os.makedirs(specs['chips_balanced'] + subset, exist_ok=True)\n",
    "    \n",
    "#     for folder in glob.glob(specs[\"chips_combined\"] + f\"{subset}/*\"):\n",
    "#         os.makedirs(specs['chips_balanced'] + subset + \"/\" + Path(folder).name, exist_ok=True)\n",
    "#         files = glob.glob(folder + \"/*\")\n",
    "#         random.shuffle(files)\n",
    "#         for f in files[:total]:\n",
    "#             f = Path(f)\n",
    "#             shutil.copy(f, specs['chips_balanced'] + subset + \"/\" + Path(folder).name + \"/\" + f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6579043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specs = {\n",
    "    'meta_class_map': group_mapping,\n",
    "    'meta_class_names': group_naming,\n",
    "    'meta_chip_size': 32,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e607be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_builder(\n",
    "    model_name=\"efficientnet\", \n",
    "    bridge=\"pooling\", \n",
    "    top_layer_neurons=256,\n",
    "    n_labels=12,\n",
    "    input_shape=(224, 224, 3),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7847ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet_pooling_256_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resizing_4 (Resizing)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 7, 7, 1792)       17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1792)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               459008    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,135,915\n",
      "Trainable params: 462,092\n",
      "Non-trainable params: 17,673,823\n",
      "_________________________________________________________________\n",
      "None\n",
      "creating ImageDataGenerators...\n",
      "Found 42000 images belonging to 12 classes.\n",
      "Found 6000 images belonging to 12 classes.\n",
      "training...\n",
      "Epoch 1/2\n",
      "1313/1313 [==============================] - 177s 131ms/step - loss: 1.7332 - accuracy: 0.3695 - val_loss: 1.7432 - val_accuracy: 0.3672\n",
      "Epoch 2/2\n",
      "1313/1313 [==============================] - 172s 131ms/step - loss: 1.5392 - accuracy: 0.4389 - val_loss: 1.6879 - val_accuracy: 0.3893\n",
      "time elapsed:     350.6s\n",
      "creating ImageDataGenerators\n",
      "Found 42000 images belonging to 12 classes.\n",
      "Found 6000 images belonging to 12 classes.\n",
      "Found 6000 images belonging to 12 classes.\n",
      "assessing performance of train dataset\n",
      "prediction of train saved\n",
      "perf_model_accuracy for train: 0.4744523763656616\n",
      "assessing performance of val dataset\n",
      "prediction of val saved\n",
      "perf_model_accuracy for val: 0.3893333375453949\n",
      "assessing performance of secret dataset\n",
      "prediction of secret saved\n",
      "perf_model_accuracy for secret: 0.3619999885559082\n"
     ]
    }
   ],
   "source": [
    "h = tools_keras.fit_phase(\n",
    "        model,\n",
    "        specs['chips_balanced'] + 'train',\n",
    "        specs['chips_balanced'] + 'validation',\n",
    "        specs['chips_balanced'] + 'secret',\n",
    "        log_folder=specs[\"folder\"] + \"logs\",\n",
    "        pred_folder=specs[\"folder\"] + \"pred\",\n",
    "        model_folder=specs[\"folder\"] + \"model\",\n",
    "        json_folder=specs[\"folder\"] + \"json\",\n",
    "        specs=model_specs,\n",
    "        epochs=2,\n",
    "        patience=5,\n",
    "        batch_size=32,\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b08516",
   "metadata": {},
   "source": [
    "## verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59e3b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "generator = datagen.flow_from_directory(\n",
    "    \"../../chips_gb/32_shuffled_sample_12_named/train/\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bc7fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    a = tf.keras.metrics.Accuracy()\n",
    "    a.update_state(y, y_pred)\n",
    "    return a.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "184a37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oy_pred_probs = model.predict(generator)\n",
    "oy_pred = numpy.argmax(oy_pred_probs, axis=1)\n",
    "y = generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e844205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47445238"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, oy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4dcf78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessible_suburbia': 0,\n",
       " 'connected_residential_neighbourhoods': 1,\n",
       " 'countryside_agriculture': 2,\n",
       " 'dense_residential_neighbourhoods': 3,\n",
       " 'dense_urban_neighbourhoods': 4,\n",
       " 'disconnected_suburbia': 5,\n",
       " 'gridded_residential_quarters': 6,\n",
       " 'open_sprawl': 7,\n",
       " 'urban_buffer': 8,\n",
       " 'urbanity': 9,\n",
       " 'warehouse_park_land': 10,\n",
       " 'wild_countryside': 11}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "393ae794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 11:02:51.694071: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_folder/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_folder\", save_format=\"tf\")\n",
    "model.save(\"model.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d06eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = keras.models.load_model(\"model_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d6dfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model_folder.predict(generator)\n",
    "y_pred = numpy.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07352ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47445238"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b595fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_h5 = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d187437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model_h5.predict(generator)\n",
    "y_pred = numpy.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecf44d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27319047"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78658d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb5ae3c-543f-46bc-8aec-2d6dbb05205e",
   "metadata": {},
   "source": [
    "# Spatial modelling of probabilities in production: all GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb4261-40ea-4980-9c45-4f885cb1ee5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "This document contains the code used to perform spatial modeling of probabilities as deployed for the case of GB. It is the production version of [`sp_model_chip_probabilities`](sp_model_chip_probabilities).\n",
    "\n",
    "The following models are fitted:\n",
    "\n",
    "1. `maxprob`: pick the top probability from those produced for the chip by the neural net\n",
    "1. `logite`: fit a Logit ensemble model using the chip probabilities from the neural net\n",
    "1. `logite_wx`: fit a Logit ensemble model using the chip probabilities _and_ the spatial lag of chip probabilities (i.g., using also the probabilities from neighboring chips)\n",
    "1. `gbt`: fit a histogram-based gradient boosted tree model using the chip probabilities from the neural net\n",
    "1. `gbt_wx`: fit a histogram-based gradient boosted tree model using the chip probabilities _and_ the spatial lag of chip probabilities (i.g., using also the probabilities from neighboring chips)\n",
    "\n",
    "These five models will be fitted to neuralnet results with the following features:\n",
    "\n",
    "- Chip size (`8`, `16`, `32`, `64`)\n",
    "- Architecture (base image classification, slided image classiffication, multi-output regression)\n",
    "\n",
    "Each combination contains three original files:\n",
    "\n",
    "- `XXX.npy`: original chips (`N x S x S x 3` with `S` being chip size)\n",
    "- `XXX_prediction.npy`: predicted probabilities (`N x 12`)\n",
    "- `XXX_labels.parquet`: geo-table with all the chip geometries, their split (`nn_train`, `nn_val`, `ml_train`, `ml_val`) and proportion of the chip assined into each label\n",
    "\n",
    "This notebooks will generate single-class predictions for each combination and store them on disk (together with their geometries and true labels). The file name format will be:\n",
    "\n",
    "> `pred_SS_AAA_model.parquet`\n",
    "\n",
    "- `SS` is size (`8`, `16`, `32`, `64`)\n",
    "- `AAA` is the architecture (`bic`, `sic`, `mor`)\n",
    "- `model` is the modelling approach used to generate the class prediction (`argmax`, `logit`, `logit_wx`, `gbt`, `gbt_wx`)\n",
    "\n",
    "To generate a single instance of the file above, we need to perform the following steps:\n",
    "\n",
    "- Pull data for the instance\n",
    "   - Read files\n",
    "   - Convert labels to `Categorical` w/ actual names\n",
    "   - Load/join probs\n",
    "- Build spatial weights for training and validation and lag probabilities\n",
    "- Train model\n",
    "- Use validation to get predictions\n",
    "- Write them out to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ed5b8a-477f-4c24-a542-16d774379f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import tools_chip_prob_modelling as tools\n",
    "from datetime import datetime\n",
    "\n",
    "from libpysal import weights\n",
    "\n",
    "data_p = '/home/jovyan/data/spatial_signatures/chip_probs/prod_probs/'\n",
    "out_p = '/home/jovyan/data/spatial_signatures/chip_probs/prod_model_outputs/'\n",
    "\n",
    "chip_sizes = [8, 16, 32, 64]\n",
    "archs = {'bic': '', 'sic': 'slided', 'mor': 'multi'}\n",
    "archs_r = {archs[i]: i for i in archs}\n",
    "\n",
    "cd2nm = tools.parse_nn_json(\n",
    "    '/home/jovyan/data/spatial_signatures/chip_probs/efficientnet_pooling_256_12.json'\n",
    ").rename(lambda i: i.replace('signature_type_', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629a536-ea4d-49af-9590-a855d82ff8d0",
   "metadata": {},
   "source": [
    "## Single instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ebed1-6170-40d1-93cd-9f34caa41fdd",
   "metadata": {},
   "source": [
    "Used for testing only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed70caeb-9e59-41ca-bd06-0785dcf99e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_ex = data_p + 'v2_8_slided'\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    out, nm = tools.premodelling_process(p_ex, cd2nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dffc80b0-6d25-4788-ad96-e96052021b05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t### 32_bic ###\n",
      "\n",
      "2022-08-17 21:52:12.912658 | <function run_maxprob at 0x7fc0982e09d0> completed successfully\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625027\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506726\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:239: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668005\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665365\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693088\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.686854\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682072\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692760\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692991\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692726\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692902\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693002\n",
      "         Iterations 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:258: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-17 21:52:15.397445 | <function run_logite at 0x7fc0982a63a0> completed successfully\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574965\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.378409\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647169\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654048\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.693062\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684661\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677947\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692598\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692931\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692489\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692762\n",
      "         Iterations 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692948\n",
      "         Iterations 3\n",
      "2022-08-17 21:52:18.267422 | <function run_logite at 0x7fc0982a63a0> completed successfully\n",
      "2022-08-17 21:52:36.719440 | <bound method BaseSearchCV.fit of GridSearchCV(cv=5, estimator=HistGradientBoostingClassifier(), n_jobs=-1,\n",
      "             param_grid={'learning_rate': [0.01, 0.05], 'max_depth': [30, None],\n",
      "                         'max_iter': [50]},\n",
      "             scoring='accuracy')> completed successfully\n",
      "2022-08-17 21:52:41.317215 | <function run_tree at 0x7fc101f3ed30> completed successfully\n",
      "2022-08-17 21:53:08.391183 | <bound method BaseSearchCV.fit of GridSearchCV(cv=5, estimator=HistGradientBoostingClassifier(), n_jobs=-1,\n",
      "             param_grid={'learning_rate': [0.01, 0.05], 'max_depth': [30, None],\n",
      "                         'max_iter': [50]},\n",
      "             scoring='accuracy')> completed successfully\n",
      "2022-08-17 21:53:13.591188 | <function run_tree at 0x7fc101f3ed30> completed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = tools.run_all_models(out, nm, out_p, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4f1e8-9f26-458d-8e23-35cd7e08754d",
   "metadata": {},
   "source": [
    "## Big loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7479cf-e142-4c85-9a75-00547995429d",
   "metadata": {},
   "source": [
    "We divide model runs in two steps to be able to work on output results while the grid search for the GBT computes. The structure and code is the same, but we first run the `maxprob` and `logite` models and then we run a big job with the boosted trees only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856db7e0-3350-44b4-84cf-69804fa89d24",
   "metadata": {},
   "source": [
    "### `maxprob`, `logite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d15cda5-721e-483b-928b-a1fefb1a2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(tools);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c2d2b-2265-42f4-8304-518db6c8c7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_p = 'big_run_log_maxprob_logite.txt'\n",
    "! rm -f $log_p\n",
    "log = f'{datetime.now()} |Log| Start\\n'\n",
    "with open(log_p, 'w') as l:\n",
    "    l.write(log)\n",
    "    \n",
    "for chip_size in chip_sizes:\n",
    "    for arch in archs:\n",
    "        p = data_p + (\n",
    "            f'v2_{chip_size}_{archs[arch]}.'\n",
    "            .replace('_.', '') # bic has no keyword\n",
    "            .strip('.')        # in data files\n",
    "        )\n",
    "        print(p)\n",
    "        with open(log_p, 'a') as l:\n",
    "            l.write(p)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            db, name = tools.premodelling_process(p, cd2nm)\n",
    "            models = ['maxprob', 'logite']\n",
    "            log = tools.run_all_models(\n",
    "                db, name, out_p, verbose=True, fo=log_p, models=models\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a061ec2-3d53-4e9d-961f-ae3c549a85d2",
   "metadata": {},
   "source": [
    "### `gbt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e40e0-a5e4-452a-9d07-e5b3c4eb4bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data/spatial_signatures/chip_probs/prod_probs/v2_8\n",
      "\t### 8_bic ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_p = 'big_run_log_gbt.txt'\n",
    "! rm -f $log_p\n",
    "log = f'{datetime.now()} |Log| Start\\n'\n",
    "with open(log_p, 'w') as l:\n",
    "    l.write(log)\n",
    "    \n",
    "for chip_size in chip_sizes:\n",
    "    for arch in archs:\n",
    "        p = data_p + (\n",
    "            f'v2_{chip_size}_{archs[arch]}.'\n",
    "            .replace('_.', '') # bic has no keyword\n",
    "            .strip('.')        # in data files\n",
    "        )\n",
    "        print(p)\n",
    "        with open(log_p, 'a') as l:\n",
    "            l.write(p)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            db, name = tools.premodelling_process(p, cd2nm)\n",
    "            models = ['gbt']\n",
    "            log = tools.run_all_models(\n",
    "                db, name, out_p, verbose=True, fo=log_p, models=models\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

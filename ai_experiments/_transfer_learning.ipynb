{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c47445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3946fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {\n",
    "    'tensor': (\n",
    "        '../urbangrammar_samba/'\n",
    "        'spatial_signatures/chips/sample.npz'\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b044e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.load(specs[\"tensor\"], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9615041",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = start + 30000\n",
    "chips = data[\"chips\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "n_classes = numpy.unique(labels).shape[0]\n",
    "assert n_classes == numpy.unique(labels).max() + 1 # no label can be missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96e8066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 15:11:47.775607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6684 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:21:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "split = int(chips.shape[0] * 0.8)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((chips[:split], labels[:split]))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((chips[split:], labels[split:]))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1100f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_and_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(224, 224, crop_to_aspect_ratio=True),\n",
    "        layers.Rescaling(scale=1 / 32)\n",
    "#         layers.RandomFlip(\"horizontal\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61ae8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 23,851,790\n",
      "Trainable params: 264,078\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.ResNet50(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False, # Do not include the ImageNet classifier at the top.\n",
    ")\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = preprocessing_and_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "predictions = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5584da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43f4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 15:11:52.868752: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-26 15:11:53.703997: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627/1627 [==============================] - 138s 81ms/step - loss: 1.1607 - sparse_categorical_accuracy: 0.4913 - val_loss: 1.1341 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 2/10\n",
      "1627/1627 [==============================] - 131s 80ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.5155 - val_loss: 1.1225 - val_sparse_categorical_accuracy: 0.4734\n",
      "Epoch 3/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.1166 - val_sparse_categorical_accuracy: 0.4752\n",
      "Epoch 4/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 1.0538 - sparse_categorical_accuracy: 0.5355 - val_loss: 1.1160 - val_sparse_categorical_accuracy: 0.4808\n",
      "Epoch 5/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 1.0357 - sparse_categorical_accuracy: 0.5438 - val_loss: 1.1199 - val_sparse_categorical_accuracy: 0.4798\n",
      "Epoch 6/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 1.0190 - sparse_categorical_accuracy: 0.5521 - val_loss: 1.1170 - val_sparse_categorical_accuracy: 0.4859\n",
      "Epoch 7/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 1.0035 - sparse_categorical_accuracy: 0.5599 - val_loss: 1.1232 - val_sparse_categorical_accuracy: 0.4841\n",
      "Epoch 8/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 0.9879 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.1288 - val_sparse_categorical_accuracy: 0.4889\n",
      "Epoch 9/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 0.9726 - sparse_categorical_accuracy: 0.5730 - val_loss: 1.1286 - val_sparse_categorical_accuracy: 0.4927\n",
      "Epoch 10/10\n",
      "1627/1627 [==============================] - 131s 81ms/step - loss: 0.9579 - sparse_categorical_accuracy: 0.5801 - val_loss: 1.1399 - val_sparse_categorical_accuracy: 0.4970\n",
      "CPU times: user 8min 36s, sys: 59.1 s, total: 9min 35s\n",
      "Wall time: 22min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e718f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 0 ns, total: 1.43 s\n",
      "Wall time: 1.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.08274615e-01, 1.17278344e-03, 2.25971016e-04, 1.58391667e-05,\n",
       "        2.30911319e-05, 2.91605983e-02, 2.07503736e-02, 2.02414487e-03,\n",
       "        1.37885145e-05, 4.38326538e-01, 1.22393385e-05, 2.77678271e-12,\n",
       "        7.05190507e-12, 4.80482376e-10],\n",
       "       [2.06201062e-01, 1.87824294e-03, 5.91045537e-05, 1.19773958e-05,\n",
       "        2.30076103e-06, 3.72314900e-02, 2.65959352e-02, 5.99628501e-03,\n",
       "        2.89296386e-05, 7.21963108e-01, 3.15322322e-05, 1.40392564e-09,\n",
       "        4.73208972e-11, 1.22205774e-08],\n",
       "       [4.09130096e-01, 2.15269509e-03, 1.05033114e-05, 7.18942147e-06,\n",
       "        7.61205740e-07, 1.17917219e-02, 4.98673022e-02, 5.45486948e-03,\n",
       "        7.85293651e-06, 5.21574914e-01, 2.11375254e-06, 1.70734542e-12,\n",
       "        1.56410269e-12, 8.20332802e-10],\n",
       "       [3.04485947e-01, 7.42831384e-04, 1.00997080e-04, 1.26559953e-05,\n",
       "        5.26443273e-07, 2.85908543e-02, 3.63336802e-02, 2.50972196e-04,\n",
       "        2.53830854e-06, 6.29477382e-01, 1.63504433e-06, 1.05667807e-12,\n",
       "        6.18766052e-13, 2.66748221e-11],\n",
       "       [5.04188895e-01, 1.39324763e-03, 5.13269370e-05, 1.72447362e-05,\n",
       "        3.83479392e-06, 2.24384349e-02, 1.81693565e-02, 1.75106246e-03,\n",
       "        2.40337267e-05, 4.51956332e-01, 6.14646706e-06, 2.60632176e-11,\n",
       "        2.34529254e-11, 8.55498672e-10],\n",
       "       [4.13320184e-01, 1.58873780e-04, 1.04766932e-05, 6.06402011e-07,\n",
       "        1.43205284e-07, 2.25541815e-02, 1.22235017e-02, 2.59038061e-04,\n",
       "        7.17460523e-07, 5.51471829e-01, 4.56380661e-07, 3.41062348e-15,\n",
       "        7.86897674e-15, 3.30171242e-12],\n",
       "       [4.46525842e-01, 1.86433143e-03, 6.84313818e-06, 7.56952886e-06,\n",
       "        1.34423351e-06, 1.42865395e-02, 3.35485418e-03, 2.72541004e-03,\n",
       "        1.40236634e-05, 5.31211078e-01, 2.21822029e-06, 3.27161284e-11,\n",
       "        2.85827650e-13, 3.87761455e-11],\n",
       "       [5.42021930e-01, 9.37060046e-04, 3.71614624e-05, 1.09748235e-05,\n",
       "        1.51776658e-06, 9.71479528e-03, 1.62490588e-02, 3.22431922e-02,\n",
       "        9.86682498e-05, 3.98681879e-01, 3.80892379e-06, 2.14061603e-12,\n",
       "        5.05896332e-11, 1.30912281e-10],\n",
       "       [4.58690435e-01, 1.16384111e-03, 3.60980653e-06, 1.04277092e-06,\n",
       "        1.67641929e-07, 1.12919677e-02, 1.26550153e-01, 3.89673258e-03,\n",
       "        1.54755162e-06, 3.98399740e-01, 7.21770562e-07, 8.94752886e-14,\n",
       "        1.24890522e-13, 4.30671054e-10],\n",
       "       [3.48774254e-01, 1.64809206e-03, 2.85527517e-06, 3.63588356e-06,\n",
       "        1.35814531e-07, 7.67222000e-03, 1.11487685e-02, 2.15840787e-02,\n",
       "        2.87433049e-05, 6.09135628e-01, 1.53265967e-06, 9.55944091e-13,\n",
       "        4.55573114e-11, 3.98270167e-10]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict(chips[-10:])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5275d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 9, 9, 9, 0, 9, 9, 0, 0, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d25774d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 9, 0, 6, 9, 1, 9, 9, 0, 9], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-10:][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b8888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975d86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_builder import model_builder, relabel, class_merger, balancer\n",
    "import tools_keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import resnet_v2, vgg19, efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d9bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {\n",
    "    'chips': \"../chips/32/\",\n",
    "    'folder': \"../urbangrammar_samba/spatial_signatures/ai/nw_32/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbcc894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107162 images belonging to 14 classes.\n",
      "Found 35721 images belonging to 14 classes.\n",
      "Found 35729 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        specs['chips'] + 'train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        specs['chips'] + 'validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "secret_datagen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
    "secret_generator = secret_datagen.flow_from_directory(\n",
    "        specs['chips'] + 'secret',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a934369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specs = {\n",
    "    'meta_class_map': {},\n",
    "    'meta_class_names': [],\n",
    "    'meta_chip_size': 32,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dfb7d4",
   "metadata": {},
   "source": [
    "## using all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise base model\n",
    "base = keras.applications.VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    ")\n",
    "base.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = vgg19.preprocess_input(inputs)\n",
    "x = base(x, training=False)\n",
    "# add bridge\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    " # add Dense relu layer\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "# add softmax classfier\n",
    "predictions = layers.Dense(14, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "        inputs,\n",
    "        predictions,\n",
    "        name=f\"vgg19_pooling_512_14\"\n",
    ")\n",
    "model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\"accuracy\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859c785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19_pooling_512_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_2 ( (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add_2 (TFOpLambda (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                7182      \n",
      "=================================================================\n",
      "Total params: 20,294,222\n",
      "Trainable params: 269,838\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:06:49.889839: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-20 15:06:49.889910: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-01-20 15:06:50.052687: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-20 15:06:50.052815: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "   1/3349 [..............................] - ETA: 33:13 - loss: 2.5238 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:06:50.822722: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-20 15:06:50.822766: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/3349 [..............................] - ETA: 18:04 - loss: 2.6300 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:06:51.143555: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-20 15:06:51.143970: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-01-20 15:06:51.158745: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 154 callback api events and 151 activity events. \n",
      "2022-01-20 15:06:51.161127: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-20 15:06:51.225822: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51\n",
      "\n",
      "2022-01-20 15:06:51.247654: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.trace.json.gz\n",
      "2022-01-20 15:06:51.264159: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51\n",
      "\n",
      "2022-01-20 15:06:51.276315: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.memory_profile.json.gz\n",
      "2022-01-20 15:06:51.320951: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51\n",
      "Dumped tool data for xplane.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19_pooling_512_14/train/plugins/profile/2022_01_20_15_06_51/85c0885614ed.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3349/3349 [==============================] - 454s 135ms/step - loss: 1.3678 - accuracy: 0.4988 - val_loss: 1.2559 - val_accuracy: 0.5313\n",
      "Epoch 2/250\n",
      "3349/3349 [==============================] - 451s 135ms/step - loss: 1.2362 - accuracy: 0.5415 - val_loss: 1.2123 - val_accuracy: 0.5479\n",
      "Epoch 3/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.1831 - accuracy: 0.5609 - val_loss: 1.2155 - val_accuracy: 0.5514\n",
      "Epoch 4/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.1486 - accuracy: 0.5704 - val_loss: 1.2284 - val_accuracy: 0.5431\n",
      "Epoch 5/250\n",
      "3349/3349 [==============================] - 451s 135ms/step - loss: 1.1175 - accuracy: 0.5820 - val_loss: 1.1409 - val_accuracy: 0.5755\n",
      "Epoch 6/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.0955 - accuracy: 0.5899 - val_loss: 1.1284 - val_accuracy: 0.5772\n",
      "Epoch 7/250\n",
      "3349/3349 [==============================] - 451s 135ms/step - loss: 1.0762 - accuracy: 0.5975 - val_loss: 1.1245 - val_accuracy: 0.5808\n",
      "Epoch 8/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.0568 - accuracy: 0.6043 - val_loss: 1.1114 - val_accuracy: 0.5888\n",
      "Epoch 9/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.0398 - accuracy: 0.6104 - val_loss: 1.1064 - val_accuracy: 0.5838\n",
      "Epoch 10/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 1.0268 - accuracy: 0.6154 - val_loss: 1.0862 - val_accuracy: 0.5919\n",
      "Epoch 11/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 1.0117 - accuracy: 0.6197 - val_loss: 1.0798 - val_accuracy: 0.5956\n",
      "Epoch 12/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 0.9993 - accuracy: 0.6256 - val_loss: 1.0833 - val_accuracy: 0.5961\n",
      "Epoch 13/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9895 - accuracy: 0.6300 - val_loss: 1.0892 - val_accuracy: 0.5881\n",
      "Epoch 14/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 0.9763 - accuracy: 0.6324 - val_loss: 1.0866 - val_accuracy: 0.5947\n",
      "Epoch 15/250\n",
      "3349/3349 [==============================] - 451s 135ms/step - loss: 0.9679 - accuracy: 0.6360 - val_loss: 1.0721 - val_accuracy: 0.6024\n",
      "Epoch 16/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 0.9588 - accuracy: 0.6397 - val_loss: 1.0745 - val_accuracy: 0.6021\n",
      "Epoch 17/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 0.9528 - accuracy: 0.6405 - val_loss: 1.0857 - val_accuracy: 0.6017\n",
      "Epoch 18/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9439 - accuracy: 0.6437 - val_loss: 1.0640 - val_accuracy: 0.6083\n",
      "Epoch 19/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9349 - accuracy: 0.6480 - val_loss: 1.0678 - val_accuracy: 0.6073\n",
      "Epoch 20/250\n",
      "3349/3349 [==============================] - 451s 135ms/step - loss: 0.9264 - accuracy: 0.6512 - val_loss: 1.0672 - val_accuracy: 0.6076\n",
      "Epoch 21/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9181 - accuracy: 0.6543 - val_loss: 1.0638 - val_accuracy: 0.6106\n",
      "Epoch 22/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9133 - accuracy: 0.6561 - val_loss: 1.1108 - val_accuracy: 0.5986\n",
      "Epoch 23/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9088 - accuracy: 0.6577 - val_loss: 1.0754 - val_accuracy: 0.6089\n",
      "Epoch 24/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.9009 - accuracy: 0.6575 - val_loss: 1.0898 - val_accuracy: 0.6074\n",
      "Epoch 25/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8983 - accuracy: 0.6622 - val_loss: 1.0733 - val_accuracy: 0.6135\n",
      "Epoch 26/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8895 - accuracy: 0.6646 - val_loss: 1.0802 - val_accuracy: 0.6072\n",
      "Epoch 27/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8841 - accuracy: 0.6669 - val_loss: 1.0865 - val_accuracy: 0.6045\n",
      "Epoch 28/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8781 - accuracy: 0.6687 - val_loss: 1.0887 - val_accuracy: 0.6081\n",
      "Epoch 29/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8726 - accuracy: 0.6709 - val_loss: 1.0700 - val_accuracy: 0.6105\n",
      "Epoch 30/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8681 - accuracy: 0.6724 - val_loss: 1.1053 - val_accuracy: 0.5940\n",
      "Epoch 31/250\n",
      "3349/3349 [==============================] - 450s 134ms/step - loss: 0.8657 - accuracy: 0.6738 - val_loss: 1.0910 - val_accuracy: 0.6136\n",
      "Epoch 32/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8629 - accuracy: 0.6749 - val_loss: 1.0921 - val_accuracy: 0.6100\n",
      "Epoch 33/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8536 - accuracy: 0.6772 - val_loss: 1.0904 - val_accuracy: 0.6107\n",
      "Epoch 34/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8508 - accuracy: 0.6778 - val_loss: 1.0884 - val_accuracy: 0.6101\n",
      "Epoch 35/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8467 - accuracy: 0.6805 - val_loss: 1.0977 - val_accuracy: 0.6105\n",
      "Epoch 36/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8444 - accuracy: 0.6810 - val_loss: 1.0889 - val_accuracy: 0.6153\n",
      "Epoch 37/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8398 - accuracy: 0.6826 - val_loss: 1.0759 - val_accuracy: 0.6184\n",
      "Epoch 38/250\n",
      "2928/3349 [=========================>....] - ETA: 42s - loss: 0.8343 - accuracy: 0.6851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8303 - accuracy: 0.6861 - val_loss: 1.1044 - val_accuracy: 0.6140\n",
      "Epoch 40/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8276 - accuracy: 0.6889 - val_loss: 1.0985 - val_accuracy: 0.6128\n",
      "Epoch 41/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8250 - accuracy: 0.6883 - val_loss: 1.1199 - val_accuracy: 0.6107\n",
      "Epoch 42/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8234 - accuracy: 0.6902 - val_loss: 1.1076 - val_accuracy: 0.6141\n",
      "Epoch 43/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8183 - accuracy: 0.6922 - val_loss: 1.1384 - val_accuracy: 0.6173\n",
      "Epoch 44/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8165 - accuracy: 0.6914 - val_loss: 1.1176 - val_accuracy: 0.6183\n",
      "Epoch 45/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8110 - accuracy: 0.6936 - val_loss: 1.1221 - val_accuracy: 0.6103\n",
      "Epoch 46/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8095 - accuracy: 0.6934 - val_loss: 1.1202 - val_accuracy: 0.6167\n",
      "Epoch 47/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.8051 - accuracy: 0.6960 - val_loss: 1.1475 - val_accuracy: 0.6081\n",
      "Epoch 48/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.8047 - accuracy: 0.6953 - val_loss: 1.1223 - val_accuracy: 0.6156\n",
      "Epoch 49/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7991 - accuracy: 0.6975 - val_loss: 1.1390 - val_accuracy: 0.6133\n",
      "Epoch 50/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7976 - accuracy: 0.6984 - val_loss: 1.1198 - val_accuracy: 0.6154\n",
      "Epoch 51/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7939 - accuracy: 0.7009 - val_loss: 1.1208 - val_accuracy: 0.6118\n",
      "Epoch 52/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7918 - accuracy: 0.6998 - val_loss: 1.1409 - val_accuracy: 0.6115\n",
      "Epoch 53/250\n",
      "3189/3349 [===========================>..] - ETA: 16s - loss: 0.7862 - accuracy: 0.7023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7840 - accuracy: 0.7047 - val_loss: 1.1515 - val_accuracy: 0.6158\n",
      "Epoch 56/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7835 - accuracy: 0.7045 - val_loss: 1.1503 - val_accuracy: 0.6136\n",
      "Epoch 57/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7765 - accuracy: 0.7060 - val_loss: 1.1829 - val_accuracy: 0.6108\n",
      "Epoch 58/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7768 - accuracy: 0.7063 - val_loss: 1.1473 - val_accuracy: 0.6192\n",
      "Epoch 59/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7750 - accuracy: 0.7061 - val_loss: 1.1600 - val_accuracy: 0.6109\n",
      "Epoch 60/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7733 - accuracy: 0.7082 - val_loss: 1.1704 - val_accuracy: 0.6109\n",
      "Epoch 61/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7690 - accuracy: 0.7095 - val_loss: 1.1619 - val_accuracy: 0.6148\n",
      "Epoch 62/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7689 - accuracy: 0.7098 - val_loss: 1.1638 - val_accuracy: 0.6143\n",
      "Epoch 63/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7676 - accuracy: 0.7094 - val_loss: 1.1705 - val_accuracy: 0.6105\n",
      "Epoch 64/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7651 - accuracy: 0.7117 - val_loss: 1.1588 - val_accuracy: 0.6144\n",
      "Epoch 65/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7630 - accuracy: 0.7117 - val_loss: 1.1811 - val_accuracy: 0.6166\n",
      "Epoch 66/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7587 - accuracy: 0.7141 - val_loss: 1.1707 - val_accuracy: 0.6192\n",
      "Epoch 67/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7574 - accuracy: 0.7136 - val_loss: 1.1764 - val_accuracy: 0.6113\n",
      "Epoch 68/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7573 - accuracy: 0.7156 - val_loss: 1.1958 - val_accuracy: 0.6138\n",
      "Epoch 69/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7526 - accuracy: 0.7158 - val_loss: 1.1951 - val_accuracy: 0.6113\n",
      "Epoch 70/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7517 - accuracy: 0.7161 - val_loss: 1.1918 - val_accuracy: 0.6174\n",
      "Epoch 71/250\n",
      "3349/3349 [==============================] - 448s 134ms/step - loss: 0.7505 - accuracy: 0.7170 - val_loss: 1.2023 - val_accuracy: 0.6103\n",
      "Epoch 72/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7486 - accuracy: 0.7176 - val_loss: 1.2139 - val_accuracy: 0.6117\n",
      "Epoch 73/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7473 - accuracy: 0.7178 - val_loss: 1.2311 - val_accuracy: 0.6157\n",
      "Epoch 74/250\n",
      "3349/3349 [==============================] - 449s 134ms/step - loss: 0.7460 - accuracy: 0.7189 - val_loss: 1.1975 - val_accuracy: 0.6143\n",
      "Epoch 00074: early stopping\n",
      "time elapsed:   33326.1s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'concatenate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6947/3215527904.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this will break after fitting with the new data input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m h = tools_keras.fit_phase(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/work/signature_ai/tools_keras.py\u001b[0m in \u001b[0;36mfit_phase\u001b[0;34m(model, train_dataset, validation_dataset, secret_dataset, log_folder, pred_folder, model_folder, json_folder, specs, chips_all, epochs, early_stopping_delta, patience, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"time elapsed: {(t1 - t0):9.1f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchips_all\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mchips_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_folder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchips_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'concatenate'"
     ]
    }
   ],
   "source": [
    "# this will break after fitting with the new data input\n",
    "h = tools_keras.fit_phase(\n",
    "        model,\n",
    "        train_generator,\n",
    "        validation_generator,\n",
    "        secret_generator,\n",
    "        log_folder=specs[\"folder\"] + \"logs\",\n",
    "        pred_folder=specs[\"folder\"] + \"pred\",\n",
    "        model_folder=specs[\"folder\"] + \"model\",\n",
    "        json_folder=specs[\"folder\"] + \"json\",\n",
    "        specs=model_specs,\n",
    "        epochs=250,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51404379",
   "metadata": {},
   "source": [
    "## using merged classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c4edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19extended_pooling_512_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_1 ( (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.nn.bias_add_1 (TFOpLambda (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 20,288,579\n",
      "Trainable params: 264,195\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:02:34.573630: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-20 14:02:34.573656: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-01-20 14:02:34.702167: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-20 14:02:34.702328: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "      1/Unknown - 1s 520ms/step - loss: 1.4285 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:02:35.373133: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-20 14:02:35.373164: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 1s 289ms/step - loss: 1.9079 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:02:35.676576: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-20 14:02:35.677019: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-01-20 14:02:35.692316: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 154 callback api events and 151 activity events. \n",
      "2022-01-20 14:02:35.694734: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-20 14:02:35.725759: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35\n",
      "\n",
      "2022-01-20 14:02:35.756118: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.trace.json.gz\n",
      "2022-01-20 14:02:35.788551: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35\n",
      "\n",
      "2022-01-20 14:02:35.807403: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.memory_profile.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4/Unknown - 1s 246ms/step - loss: 1.6831 - accuracy: 0.4297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:02:35.884515: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35\n",
      "Dumped tool data for xplane.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw_32/logs/vgg19extended_pooling_512_3/train/plugins/profile/2022_01_20_14_02_35/85c0885614ed.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  37870/Unknown - 3840s 101ms/step - loss: 0.4134 - accuracy: 0.8268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6947/3611277248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# this will break after fitting with the new data input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m h = tools_keras.fit_phase(\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmerged_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/work/signature_ai/tools_keras.py\u001b[0m in \u001b[0;36mfit_phase\u001b[0;34m(model, train_dataset, validation_dataset, secret_dataset, log_folder, pred_folder, model_folder, json_folder, specs, chips_all, epochs, early_stopping_delta, patience, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     h = model.fit(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "# combine classes\n",
    "group_mapping = {\n",
    "    0: ['9_0', '9_1', '9_2', '9_4', '9_5', '2_0', '2_1', '2_2'],\n",
    "    1: ['1_0', '3_0', '5_0', '6_0', '8_0'],\n",
    "    2: ['0_0', '4_0', '7_0']\n",
    "}\n",
    "all_groups = sorted(chain(*group_mapping.values()))\n",
    "# define a mapping from old classes to new classes (i.e. 0,1 -> 0 and 2,3 -> 1)\n",
    "# the original classes are sorted and turned to ints\n",
    "old_to_new = []\n",
    "for g in all_groups:\n",
    "    for k in group_mapping.keys():\n",
    "        if g in group_mapping[k]:\n",
    "            old_to_new.append(k)\n",
    "old_to_new = np.array(old_to_new).astype(int)\n",
    "\n",
    "# the wrapping generator\n",
    "def merged_classes(generator):\n",
    "    for data, labels in generator:\n",
    "        labels = old_to_new[labels.astype(int)]\n",
    "\n",
    "        yield data, labels\n",
    "\n",
    "        \n",
    "# initialise base model\n",
    "base = keras.applications.VGG19(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    ")\n",
    "base.trainable = False\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = vgg19.preprocess_input(inputs)\n",
    "x = base(x, training=False)\n",
    "# add bridge\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    " # add Dense relu layer\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "# add softmax classfier\n",
    "predictions = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "        inputs,\n",
    "        predictions,\n",
    "        name=f\"vgg19extended_pooling_512_3\"\n",
    ")\n",
    "model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "# this will break after fitting with the new data input\n",
    "h = tools_keras.fit_phase(\n",
    "        model,\n",
    "        merged_classes(train_generator),\n",
    "        merged_classes(validation_generator),\n",
    "        merged_classes(secret_generator),\n",
    "        log_folder=specs[\"folder\"] + \"logs\",\n",
    "        pred_folder=specs[\"folder\"] + \"pred\",\n",
    "        model_folder=specs[\"folder\"] + \"model\",\n",
    "        json_folder=specs[\"folder\"] + \"json\",\n",
    "        specs=model_specs,\n",
    "        epochs=250,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "#         steps_per_epoch=107162 // 32  # total train // batch size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d0bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

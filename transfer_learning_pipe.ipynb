{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aae35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_builder import model_builder, relabel, class_merger, balancer\n",
    "\n",
    "import model_builder\n",
    "import tools_keras\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ac288",
   "metadata": {},
   "source": [
    "Load chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101aa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {\n",
    "    'tensor': (\n",
    "        '../urbangrammar_samba/'\n",
    "        'spatial_signatures/chips/sample.npz'\n",
    "    ),\n",
    "    'folder': \"../urbangrammar_samba/spatial_signatures/ai/nw/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc2703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.load(specs[\"tensor\"], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498b1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = data[\"chips\"]\n",
    "labels = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22577bf8",
   "metadata": {},
   "source": [
    "Shuffle data to ensure full randomness before splitting to test, validation and secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bcca44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "\n",
    "shuffled_idx = numpy.arange(0, chips.shape[0])\n",
    "numpy.random.shuffle(shuffled_idx)\n",
    "\n",
    "chips = chips[shuffled_idx]\n",
    "labels = labels[shuffled_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251a68a",
   "metadata": {},
   "source": [
    "Merge groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d9bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping = [\n",
    "    ['9_0', '9_1', '9_2', '9_4', '9_5', '2_0', '2_1', '2_2'],\n",
    "    ['1_0', '3_0', '5_0', '6_0', '8_0'],\n",
    "    ['0_0', '4_0', '7_0']\n",
    "]\n",
    "labels = class_merger(labels, group_mapping)\n",
    "\n",
    "# If you don't want to merge groups, use `relabel` to ensure your labels are in the proper format\n",
    "# labels = relabel(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bc3cb",
   "metadata": {},
   "source": [
    "Drop chips from excessive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43067d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of selected chips: 18841 out of 65042\n",
      "Counts:\n",
      " {0: 907, 1: 8864, 2: 9070}\n"
     ]
    }
   ],
   "source": [
    "mask = balancer(labels, max_ratio=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c504ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[mask]\n",
    "chips = chips[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd4d51",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421b4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = chips / (chips.max() / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07518471",
   "metadata": {},
   "source": [
    "Split data into train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df40495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 15:20:17.535031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6684 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:21:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "split_1 = int(chips.shape[0] * 0.6)\n",
    "split_2 = int(chips.shape[0] * 0.8)\n",
    "\n",
    "\n",
    "# assert that all labels are present in train and validation datasets\n",
    "assert (numpy.unique(labels[:split_1]) == numpy.unique(labels[split_1:split_2])).all()\n",
    "assert (numpy.unique(labels[:split_1]) == numpy.unique(labels[split_2:])).all()\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((chips[:split_1], labels[:split_1]))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((chips[split_1:split_2], labels[split_1:split_2]))\n",
    "secret_dataset = tf.data.Dataset.from_tensor_slices((chips[split_2:], labels[split_2:]))\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "validation_dataset = validation_dataset.batch(batch_size=batch_size)\n",
    "secret_dataset = secret_dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf59fc",
   "metadata": {},
   "source": [
    "Create model and fit in a loop over options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5168bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 15:20:39.211599: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 15:20:39.211628: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 15:20:39.211656: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2021-12-13 15:20:39.275459: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 15:20:39.275662: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "2021-12-13 15:20:44.749640: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-13 15:20:45.570276: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n",
      "2021-12-13 15:20:48.704494: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-13 15:20:48.704525: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-13 15:20:49.620278: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 15:20:49.620828: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2021-12-13 15:20:49.657966: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 5785 callback api events and 4632 activity events. \n",
      "2021-12-13 15:20:49.692408: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-13 15:20:49.822582: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49\n",
      "\n",
      "2021-12-13 15:20:49.903846: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.trace.json.gz\n",
      "2021-12-13 15:20:49.956161: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49\n",
      "\n",
      "2021-12-13 15:20:49.969054: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.memory_profile.json.gz\n",
      "2021-12-13 15:20:50.029840: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49\n",
      "Dumped tool data for xplane.pb to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ../urbangrammar_samba/spatial_signatures/ai/nw/logs/resnet50_flatten_128_3/train/plugins/profile/2021_12_13_15_20_49/985b7fd52aa6.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_specs = {\n",
    "    'meta_class_map': group_mapping,\n",
    "    'meta_class_names': [\"centres\", \"periphery\", \"countryside\"],\n",
    "    'meta_chip_size': 32,\n",
    "}\n",
    "\n",
    "for model_name, bridge, neurons in product([\"resnet50\", \"vgg19\", \"efficientnet\"], [\"flatten\", \"pooling\"], [128, 256, 512]):\n",
    "    model = model_builder.model_builder(\n",
    "        model_name=model_name, \n",
    "        bridge=bridge, \n",
    "        top_layer_neurons=neurons,\n",
    "        n_labels=3,\n",
    "    )\n",
    "\n",
    "    h = tools_keras.fit_phase(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        validation_dataset,\n",
    "        secret_dataset,\n",
    "        log_folder=specs[\"folder\"] + \"logs\",\n",
    "        pred_folder=specs[\"folder\"] + \"pred\",\n",
    "        model_folder=specs[\"folder\"] + \"model\",\n",
    "        json_folder=specs[\"folder\"] + \"json\",\n",
    "        specs=model_specs,\n",
    "        epochs=250,\n",
    "        patience=5,\n",
    "        verbose=False,\n",
    "\n",
    "    )\n",
    "    print(model_name, bridge, neurons, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "016199de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools_keras.flush(specs[\"folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6bc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

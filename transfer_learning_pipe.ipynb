{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff91d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_builder import model_builder, relabel, class_merger, balancer\n",
    "import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ee2ad",
   "metadata": {},
   "source": [
    "Load chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bdbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {\n",
    "    'tensor': (\n",
    "        '../urbangrammar_samba/'\n",
    "        'spatial_signatures/chips/sample.npz'\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ca7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {'tensor': '../sample(1).npz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d78202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.load(specs[\"tensor\"], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3775ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = data[\"chips\"]\n",
    "labels = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d074b0e",
   "metadata": {},
   "source": [
    "Merge groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbdd6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping = [\n",
    "    ['9_0', '9_1', '9_2', '9_4', '9_5', '2_0', '2_1', '2_2'],\n",
    "    ['1_0', '3_0', '5_0', '6_0', '8_0'],\n",
    "    ['0_0', '4_0', '7_0']\n",
    "]\n",
    "labels = class_merger(labels, group_mapping)\n",
    "\n",
    "# If you don't want to merge groups, use `relabel` to ensure your labels are in the proper format\n",
    "# labels = relabel(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e2838",
   "metadata": {},
   "source": [
    "Drop chips from excessive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582d74b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of selected chips: 27911 out of 65042\n",
      "Counts:\n",
      " {0: 907, 1: 8864, 2: 18140}\n"
     ]
    }
   ],
   "source": [
    "mask = balancer(labels, max_ratio=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09cff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[mask]\n",
    "chips = chips[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9efff",
   "metadata": {},
   "source": [
    "Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e38b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = chips / (chips.max() / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e3cea",
   "metadata": {},
   "source": [
    "Shuffle data to ensure full randomness before splitting to test, validation and secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3737d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "\n",
    "shuffled_idx = numpy.arange(0, chips.shape[0])\n",
    "numpy.random.shuffle(shuffled_idx)\n",
    "\n",
    "chips = chips[shuffled_idx]\n",
    "labels = labels[shuffled_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77308f2b",
   "metadata": {},
   "source": [
    "Split data into train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c17863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 18:19:50.808920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:50.870053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:50.870381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:50.871525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:50.872044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:50.872746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:51.184396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:51.184766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:51.185014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-10 18:19:51.185241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6023 MB memory:  -> device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "split = int(chips.shape[0] * 0.8)\n",
    "\n",
    "# assert that all labels are present in train and validation datasets\n",
    "assert (numpy.unique(labels[:split]) == numpy.unique(labels[split:])).all()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((chips[:split], labels[:split]))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((chips[split:], labels[split:]))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bcbc0",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87b76fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71688192/71686520 [==============================] - 32s 0us/step\n",
      "71696384/71686520 [==============================] - 32s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(model_builder)\n",
    "model = model_builder.model_builder(\n",
    "    model_name=\"efficientnet\", \n",
    "    bridge=\"flatten\", \n",
    "    top_layer_neurons=512,\n",
    "    n_labels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4011716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet_flatten_512_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resizing (Resizing)          (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb4 (Functional)  (None, 7, 7, 1792)        17673823  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 87808)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               44958208  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 62,633,570\n",
      "Trainable params: 44,959,747\n",
      "Non-trainable params: 17,673,823\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ad89a",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ceee183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 18:20:53.367791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-10 18:20:54.547604: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 103s 136ms/step - loss: 2.9217 - accuracy: 0.6861 - val_loss: 0.7451 - val_accuracy: 0.6722\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 1\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b162a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(chips[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5bea407",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = numpy.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "66bdf18f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_940/4149119397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools_keras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m tools_keras.build_meta_json(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     { # This would be filled from the training loop\n",
      "\u001b[0;32m/workspace/work/tools_keras.py\u001b[0m in \u001b[0;36mbuild_meta_json\u001b[0;34m(model, specs, xy_train, xy_val, xy_secret, xy_all)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'secret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import tools_keras\n",
    "from importlib import reload\n",
    "reload(tools_keras)\n",
    "tools_keras.build_meta_json(\n",
    "    model, \n",
    "    { # This would be filled from the training loop\n",
    "        'meta_class_map': None,\n",
    "        'meta_class_names': None,\n",
    "        'meta_chip_size': None\n",
    "    },\n",
    "    test_dataset, # Taining set\n",
    "    test_dataset, # Validation set\n",
    "    test_dataset, # Secret set\n",
    "    test_dataset, # Full set\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
